nfolds = max(fold_ind)
if(!all.equal(sort(unique(fold_ind)), 1:nfolds)) stop("Invalid fold partition.")
cv_errors = numeric(nfolds)
for(fold in 1:nfolds) {
# Fitting logistics regression model over the data
tmp_fit = glm(y~., data = Xy[fold_ind != fold,], family = "binomial")
# Predicting the response variable
yhat_log = predict(tmp_fit, Xy[fold_ind == fold,], type = "response")
# Rounding the prediction probabilities of response variable
yhat = ifelse(yhat_log > 0.5, 1, 0)
yobs = y[fold_ind==fold]
# Calculating the test error and storing it
cv_errors[fold] = 1-mean((yobs == yhat))
}
fold_sizes = numeric(nfolds)
for(fold in 1:nfolds) fold_sizes[fold] = length(which(fold_ind==fold))
test_error = weighted.mean(cv_errors, w=fold_sizes)
return(test_error)
}
# Calling cross validation function with required parameters
# 0.03367496
(log_cv_error = log_cv(brst_cncr_df[,1:6], brst_cncr_df$y, fold_index))
library(glmnet)
set.seed(3253)
# Splitting training & test data in features and response variable
x_train = as.matrix(brst_cncr[,1:9])
y_train = brst_cncr$y
# Grid values for the tuning parameter
grid = 10^seq(-5, 2, length.out=100)
# LASSO fit for each value of the tuning parameter
lasso_fit = glmnet(brst_cncr[,1:9], brst_cncr$y, family="binomial", alpha=1, standardize=FALSE, lambda=grid)
# Plotting the effect of the tuning parameter on parameter estimates
plot(lasso_fit, xvar="lambda", col=rainbow(p), label=TRUE)
# Perform k-fold cross-validation to find optimal lambda value for Lasso
lasso_reg_cv = cv.glmnet(x_train, y_train, alpha = 1, standardize = FALSE, grid=grid, foldid = fold_index)
plot(lasso_reg_cv)
grp_q = qda(brst_cncr$y ~ ., data=brst_cncr[,-10])
grp_q$means
grp$means
grp = lda(brst_cncr$y ~ ., data=brst_cncr[,-10])
grp$means
#            Syed Mohib Raza
#            Student No: 200740241
#            MAS 8404 - Statistical Learning for Data Science
#Reducing interpretability
# install.packages("mlbench")
# install.packages("caTools")
# Loading mlbench package
library(mlbench)
library(caTools)
# Loading data
data(BreastCancer)
# Checking dimension of data
dim(BreastCancer)
# Print first few rows
head(BreastCancer)
# Remove rows with NA value in any column
df = na.omit(BreastCancer)
dim(df)
# Tabulate the categorical values
table(df$Class)
# Extracting dependent variable
y = df[,11]
# Converting categorical values in binomial
# below funct converts in sequence of number as per the category so benign =1 and malignant =2
y = as.integer(y)
# benign = 0, malignant = 1
y = y-1
# Displaying no. of rows for 0 & 1 dependent variable
table(y)
# MARGIN 1 = Column wise, 2 = Row wise
# Converting and extracting the predictor variables
x = apply(df[,c(2:10)], MARGIN = 2, FUN = as.numeric)
# Reform the data frame
brst_cncr = data.frame(x,y)
## Store n and p
n = nrow(brst_cncr); p = ncol(brst_cncr) - 1
# Producing a pair plot with red as dependent variable colour
# Linear relationship between size and shape of cell
pairs(brst_cncr[,1:9], col = brst_cncr[,10]+1)
#-------------------------------------------------- Finding optimal number of features
# Use subset because low features (Subset method is computationally expensive)
# More features means better to use stepwise (Stepwise is less computationally expensive)
# Load the bestglm package
library(bestglm)
# Apply best subset selection
bss_fit_AIC = bestglm(brst_cncr,family=binomial,IC="AIC")
bss_fit_BIC = bestglm(brst_cncr,family=binomial,IC="BIC")
# Examine the results
bss_fit_AIC$Subsets
bss_fit_BIC$Subsets
# Identify best-fitting models
(best_AIC = bss_fit_AIC$ModelReport$Bestk)
(best_BIC = bss_fit_BIC$ModelReport$Bestk)
# Multi-panel plotting
par(mfrow=c(1,2))
# Produce plots, highlighting optimal value of k
plot(0:p, bss_fit_AIC$Subsets$AIC,xlab="Number of predictors",ylab="AIC",type="b")
points(best_AIC, bss_fit_AIC$Subsets$AIC[best_AIC+1],col="red",pch=16)
plot(0:p, bss_fit_BIC$Subsets$BIC,xlab="Number of predictors",ylab="BIC",type="b")
points(best_BIC, bss_fit_BIC$Subsets$BIC[best_BIC+1],col="red",pch=16)
# AIC
# From the plot
pstar=7
# Check which predictors are in the 7-predictor model
bss_fit_AIC$Subsets[pstar+1,]
# Construct a reduced data set containing only the selected predictor.
(indices = as.logical(bss_fit_AIC$Subsets[pstar+1, 2:(p+1)])) #row=8 (index 7), column = 10
# Select the columns where it's indices are true
brst_cncr_df_aic = data.frame(x[,indices], y)
# BIC
# From the plot
pstar=5
# Check which predictors are in the 7-predictor model
bss_fit_AIC$Subsets[pstar+1,]
# Construct a reduced data set containing only the selected predictor.
(indices = as.logical(bss_fit_AIC$Subsets[pstar+1, 2:(p+1)])) #row=8 (index 7), column = 10
# Select the columns where it's indices are true
brst_cncr_df_bic = data.frame(x[,indices], y)
# Compromise between AIC and BIC
# From the plot
pstar=6
# Check which predictors are in the 7-predictor model
bss_fit_AIC$Subsets[pstar+1,]
# Construct a reduced data set containing only the selected predictor.
(indices = as.logical(bss_fit_AIC$Subsets[pstar+1, 2:(p+1)])) #row=8 (index 7), column = 10
# Select the columns where it's indices are true
brst_cncr_df = data.frame(x[,indices], y)
#-------------------------------------------------- Logistics regression
# Set the seed to replicate the results
set.seed(2534)
# Fitting the logistics regression model
logistics_reg = glm(y~., data = brst_cncr_df, family = "binomial")
# Not necessary
# Inspecting the p-value column in the table, we see that only cl.thickness has a coefficient which is significantly different from zero when testing at the 5% level.
# In other words this suggests that the predictor in question adds very little in terms of forecasting
summary(logistics_reg)
# Predicting dependent variable for test data
prediction_log = predict(logistics_reg, brst_cncr_df, type = "response")
# Compute fitted values
yhat_log=ifelse(prediction_log > 0.5, 1, 0)
# Generating confusion matrix
# 434 + 229 right | 10 + 10 wrong
(confusion_matrix_log=table(Observed=brst_cncr_df$y,Predicted=yhat_log))
# Calculating train error for logistic regression
# 0.02928258
(log_tst_err = (1-mean(brst_cncr_df$y==yhat_log)))
#-------------------------------------------------- Cross validation based test error - logistic regression
# Cross validation for calculating test error
# 10-fold cross validation
nfolds = 10
# Sample fold-assignment index
fold_index = sample(nfolds, n, replace=TRUE)
# Print first few fold-assignments
head(fold_index)
# Cross Validation function
log_cv = function(X1, y, fold_ind) {
# Creating data frame
Xy = data.frame(X1, y=y)
nfolds = max(fold_ind)
if(!all.equal(sort(unique(fold_ind)), 1:nfolds)) stop("Invalid fold partition.")
cv_errors = numeric(nfolds)
for(fold in 1:nfolds) {
# Fitting logistics regression model over the data
tmp_fit = glm(y~., data = Xy[fold_ind != fold,], family = "binomial")
# Predicting the response variable
yhat_log = predict(tmp_fit, Xy[fold_ind == fold,], type = "response")
# Rounding the prediction probabilities of response variable
yhat = ifelse(yhat_log > 0.5, 1, 0)
yobs = y[fold_ind==fold]
# Calculating the test error and storing it
cv_errors[fold] = 1-mean((yobs == yhat))
}
fold_sizes = numeric(nfolds)
for(fold in 1:nfolds) fold_sizes[fold] = length(which(fold_ind==fold))
test_error = weighted.mean(cv_errors, w=fold_sizes)
return(test_error)
}
# Calling cross validation function with required parameters
# 0.03367496
(log_cv_error = log_cv(brst_cncr_df[,1:6], brst_cncr_df$y, fold_index))
#-------------------------------------------------- Lasso ----------------------------------------------------------------------------
# If and when two more independent variables are highly correlated with each other.
# It causes the model to perform poorly when it is applied on a new data set.
# To avoid this problem we use ridge and Lasso.
# Ridge vs Lasso
# In cases with small features we generally use [lasso].
# It is able to remove insignificant features by shrinking them to 0.
# And we know from subset selection that 6 variables have very high importance
library(glmnet)
set.seed(3253)
# Splitting training & test data in features and response variable
x_train = as.matrix(brst_cncr[,1:9])
y_train = brst_cncr$y
# Grid values for the tuning parameter
grid = 10^seq(-5, 2, length.out=100)
# LASSO fit for each value of the tuning parameter
lasso_fit = glmnet(brst_cncr[,1:9], brst_cncr$y, family="binomial", alpha=1, standardize=FALSE, lambda=grid)
# Plotting the effect of the tuning parameter on parameter estimates
plot(lasso_fit, xvar="lambda", col=rainbow(p), label=TRUE)
# Perform k-fold cross-validation to find optimal lambda value for Lasso
lasso_reg_cv = cv.glmnet(x_train, y_train, alpha = 1, standardize = FALSE, grid=grid, foldid = fold_index)
plot(lasso_reg_cv)
# Finding min lambda value which is the optimal tuning parameter
# 0.01132249
(lasso_min_lambda = lasso_reg_cv$lambda.min)
# Find the parameter estimates associated with optimal value of the tuning parameter
coef(lasso_fit, s=lasso_min_lambda)
# Displaying coefficients
coef(lasso_reg_cv)
# Displaying test error
# 0.03732508
lasso_reg_cv$cvm[which(lasso_reg_cv$lambda == lasso_min_lambda)]
# Note that this is a key difference between ridge regression and lasso regression.
# Ridge regression shrinks all coefficients towards zero,
# but lasso regression has the potential to remove predictors from the model by shrinking the coefficients completely to zero.
#---------------------------------------------------------- LDA ----------------------------------------------------------------------------
# Load MASS ans nclSLR package
library(MASS)
library(nclSLR)
linDA(variables= as.matrix(brst_cncr[-10]),  group=brst_cncr$y)
# define the function for cross validation.
reg_cv_lda = function(X1, y, fold_ind) {
Xy = data.frame(X1, y=y)
nfolds = max(fold_ind)
if(!all.equal(sort(unique(fold_ind)), 1:nfolds)) stop("Invalid fold partition.")
cv_errors = numeric(nfolds)
for(fold in 1:nfolds) {
# Fitting LDA
tmp_fit_lda = lda(Xy[fold_ind!=fold,]$y ~ ., data=Xy[fold_ind!=fold,][,-10])
# Predicting the response variable
phat_lda = predict(tmp_fit_lda, Xy[fold_ind==fold,][-10])
# convert prediction into numeric from probability
yhat_lda = phat_lda$class
yobs = y[fold_ind==fold]
# Calculating the test error and storing it
cv_errors[fold] = 1 - mean((yobs == yhat_lda))
}
fold_sizes = numeric(nfolds)
for(fold in 1:nfolds) fold_sizes[fold] = length(which(fold_ind==fold))
test_error = weighted.mean(cv_errors, w=fold_sizes)
return(test_error)
}
# 0.04099561
(lda_error = reg_cv_lda(brst_cncr[,-10],brst_cncr$y, fold_index))
grp = lda(brst_cncr$y ~ ., data=brst_cncr[,-10])
grp$means
head(fold_index)
grp_q = qda(brst_cncr$y ~ ., data=brst_cncr[,-10])
grp_q$means
#            Syed Mohib Raza
#            Student No: 200740241
#            MAS 8404 - Statistical Learning for Data Science
#Reducing interpretability
# install.packages("mlbench")
# install.packages("caTools")
# Loading mlbench package
library(mlbench)
library(caTools)
# Loading data
data(BreastCancer)
# Checking dimension of data
dim(BreastCancer)
# Print first few rows
head(BreastCancer)
# Remove rows with NA value in any column
df = na.omit(BreastCancer)
dim(df)
# Tabulate the categorical values
table(df$Class)
# Extracting dependent variable
y = df[,11]
# Converting categorical values in binomial
# below funct converts in sequence of number as per the category so benign =1 and malignant =2
y = as.integer(y)
# benign = 0, malignant = 1
y = y-1
# Displaying no. of rows for 0 & 1 dependent variable
table(y)
# MARGIN 1 = Column wise, 2 = Row wise
# Converting and extracting the predictor variables
x = apply(df[,c(2:10)], MARGIN = 2, FUN = as.numeric)
# Reform the data frame
brst_cncr = data.frame(x,y)
## Store n and p
n = nrow(brst_cncr); p = ncol(brst_cncr) - 1
# Producing a pair plot with red as dependent variable colour
# Linear relationship between size and shape of cell
pairs(brst_cncr[,1:9], col = brst_cncr[,10]+1)
2917%60
2917 % 60
2917 / 60
setwd("C:/Users/Acer/OneDrive - Newcastle University/Newcastle/CSC8631 - EDA & Data Managament/Project_mooc")
source("C:/Users/Acer/OneDrive - Newcastle University/Newcastle/CSC8631 - EDA & Data Managament/Project_mooc/src/eda.R")
source("C:/Users/Acer/Downloads/eda.R")
source("C:/Users/Acer/OneDrive - Newcastle University/Newcastle/CSC8631 - EDA & Data Managament/Project_mooc/src/eda.R")
## Basic understanding of data
#For batch 1:
archetype_1 = cyber.security.1_archetype.survey.responses
(dim(archetype_1))#checking the dimension of the archetype dataset
(summary((archetype_1)))
gender_plot = ggplot(enrolment_1, aes(gender,fill=gender)) + geom_bar()
enrolment_1 = cyber.security.1_enrolments
(dim(enrolment_1))
(summary((enrolment_1)))
source("C:/Users/Acer/OneDrive - Newcastle University/Newcastle/CSC8631 - EDA & Data Managament/Project_mooc/src/eda.R")
## Basic understanding of data
#For batch 1:
archetype_1 = cyber.security.1_archetype.survey.responses
(dim(archetype_1))#checking the dimension of the archetype dataset
(summary((archetype_1)))
leaving_survey_1 = cyber.security.1_question.response
(dim(question_response_1))
(summary((question_response_1)))
(dim(leaving_survey_1))
(summary((leaving_survey_1)))
leaving_survey_1 = cyber.security.1_question.response
## Basic understanding of data
#For batch 1:
archetype_1 = cyber.security.1_archetype.survey.responses
(dim(archetype_1))#checking the dimension of the archetype dataset
(summary((archetype_1)))
enrolment_1 = cyber.security.1_enrolments
(dim(enrolment_1))
(summary((enrolment_1)))
(dim(leaving_survey_1))
(summary((leaving_survey_1)))
question_response_1 = cyber.security.1_question.response
(dim(question_response_1))
(summary((question_response_1)))
step_activity_1 = cyber
(dim(step_activity_1))
(summary((step_activity_1)))
weekly_sentiment_1 = cyber.security.1_weekly.sentiment.survey.responses
(dim(weekly_sentiment_1))
(summary((weekly_sentiment_1)))
colnames(enrolment_1)
unique(enrolment_1$role)
gender_plot = ggplot(enrolment_1, aes(gender,fill=gender)) + geom_bar()
gender_plot
learners_gender = b %>%
gather(key, value, -Iteration) %>%
ggplot(aes(x=Iteration , y=value, fill = key)) +
geom_col(position = "dodge")
png(file="./graphs/gender_learners.png",width = 1920, height = 1080)
grid.arrange(learners_gender)
dev.off()
h1 = ggplot() +
geom_bar(highest_education_level1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,750)) + theme(axis.text.x = element_text(angle = 90))
# # Highest education level of ppl who finished the course for all 7 batches
high_edu_lvl1 = cyber.security.1_enrolments$highest_education_level
h1_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
# # Highest education level of ppl who finished the course for all 7 batches
high_edu_lvl1 = cyber.security.1_enrolments
h1_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h1_fp
h2_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h3_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h4_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h5_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h6_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h7_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300))+ theme(axis.text.x = element_text(angle = 90))
edu_lvl_fp_plot = grid.arrange(h1_fp,h2_fp,h3_fp,h4_fp,h5_fp,h6_fp,h7_fp)
library(ggplot2)
edu_lvl_fp_plot = grid.arrange(h1_fp,h2_fp,h3_fp,h4_fp,h5_fp,h6_fp,h7_fp)
h1_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h2_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h3_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h4_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h5_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h6_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h7_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300))+ theme(axis.text.x = element_text(angle = 90))
edu_lvl_fp_plot = grid.arrange(h1_fp,h2_fp,h3_fp,h4_fp,h5_fp,h6_fp,h7_fp)
png(file="./graphs/participants_edu_lvl.png",width = 1920, height = 1080)
grid.arrange(h1_fp,h2_fp,h3_fp,h4_fp,h5_fp,h6_fp,h7_fp)
dev.off()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath('..'))
library(ProjectTemplate)
load.project()
# Run data analysis script
source("src/eda.R")
edu_plot
box_plot
summary(video_stats$north_america_views_percentage)
summary(video_stats$asia_views_percentage)
summary(video_stats$europe_views_percentage)
summary(video_stats$europe_views_percentage)
summary(video_stats$oceania_views_percentage)
asia_transcript
head(df_clean)
h1_fp = ggplot() +
geom_bar(high_edu_lvl1, mapping = aes(highest_education_level,fill=highest_education_level), stat = "count", position = position_dodge()) +
coord_cartesian(ylim = c(0,300)) + theme(axis.text.x = element_text(angle = 90))
h1_fp
View(cyber.security.1_enrolments)
View(cyber.security.1_enrolments)
head(enrol)
getwd()
x = getwd()
x+hghj
x+ 'hghj'
class(x)
class('klkd')
x+x
enrol_vs_comp_plot = ggplot(enrol, aes(x=Batch, y=Count, group=Status)) +
geom_line(aes(color=Status), size = 1)+
geom_point(aes(color=Status),size = 4)+
ylab("No. of learners")
enrol_vs_comp_plot
View(enrol)
Count
enrol_vs_comp_plot = ggplot(enrol, aes(x=enrol$enrolled_at, group=employment_status)) +
geom_line(aes(color=Status), size = 1)+
geom_point(aes(color=Status),size = 4)+
ylab("No. of learners")
enrol_vs_comp_plot
enrol_vs_comp_plot = ggplot(enrol, aes(x=enrol$enrolled_at, group=employment_status)) +
geom_line(aes(color=Status), size = 1)+
geom_point(aes(color=Status),size = 4)+
ylab("No. of learners")
enrol_vs_comp_plot
enrol_vs_comp_plot
ggplot(enrol, aes(x=enrol$enrolled_at, group=employment_status)) +
geom_line(aes(color=Status), size = 1)+
geom_point(aes(color=Status),size = 4)+
ylab("No. of learners")
enrol_vs_comp_plot = ggplot(enrol, aes(x=enrol$enrolled_at, group=employment_status)) +
geom_line(aes(color=employment_status), size = 1)+
geom_point(aes(color=employment_status),size = 4)+
ylab("No. of learners")
enrol_vs_comp_plot
enrol_vs_comp_plot = ggplot(enrol, aes(x=enrolled_at, y=unenrolled_at group=employment_status)) +
geom_line(aes(color=employment_status), size = 1)+
geom_point(aes(color=employment_status),size = 4)+
ylab("No. of learners")
enrol_vs_comp_plot = ggplot(enrol, aes(x=enrolled_at, y=unenrolled_at, group=employment_status)) +
geom_line(aes(color=employment_status), size = 1)+
geom_point(aes(color=employment_status),size = 4)+
ylab("No. of learners")
enrol_vs_comp_plot
enrol_vs_comp_plot = ggplot(enrol, aes(x=enrol$highest_education_level, y=country, group=employment_status)) +
geom_line(aes(color=employment_status), size = 1)+
geom_point(aes(color=employment_status),size = 4)+
ylab("No. of learners")
enrol_vs_comp_plot
video_stats_views_plot = ggplot(data = all_views, aes(x=title,y= value, fill = video_stats , group = video_stats, color = video_stats)) +
geom_line(size = 1) +
geom_point(size = 2) +
ylab("Video stats") +
theme(axis.text.x = element_text(angle = 45, hjust =1))+
scale_fill_brewer(palette = "Set3")
video_stats_views_plot = ggplot(data = video_stats, aes(x=title,y= value, fill = video_stats , group = video_stats, color = video_stats)) +
geom_line(size = 1) +
geom_point(size = 2) +
ylab("Video stats") +
theme(axis.text.x = element_text(angle = 45, hjust =1))+
scale_fill_brewer(palette = "Set3")
video_stats_views_plot
View(video_stats)
continent_plot = ggplot(data = video_stats, aes(x=col.names(video_stats[c(22:28)]), y= view_percentage, fill = col.names(video_stats[c(22:28)]) , group = col.names(video_stats[c(22:28)]), color = ))+
geom_bar(position="dodge", stat="identity") +
labs(fill = "Continents") +
xlab("continents")+
ylab("% learner views from each continents")+
theme(axis.text.x = element_text(angle = 45, hjust =1)) +
scale_fill_brewer(palette = "Set3")
continent_plot
colnames(video_stats)
continent_plot = ggplot(data = video_stats, aes(x=colnames(video_stats[c(22:28)]), y= view_percentage, fill = colnames(video_stats[c(22:28)]) , group = colnames(video_stats[c(22:28)]), color = ))+
geom_bar(position="dodge", stat="identity") +
labs(fill = "Continents") +
xlab("continents")+
ylab("% learner views from each continents")+
theme(axis.text.x = element_text(angle = 45, hjust =1)) +
scale_fill_brewer(palette = "Set3")
colnames(video_stats)
continent_plot
edu_plot
edu_plot
employment_plot
